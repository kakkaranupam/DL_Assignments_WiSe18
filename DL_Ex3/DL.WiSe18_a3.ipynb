{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Exercise (Chapter 7 & 8)\n",
    "This exercise focuses on optimization and regularization.\n",
    "\n",
    "In the optimization part, we will\n",
    "- implement the Adam optimizer\n",
    "- compare Adam, SGD, SGD with Momentum\n",
    "- implement and analyze some learning rate schedules\n",
    "\n",
    "In the regularization part, we will\n",
    "- implement Dropout\n",
    "- implement L1/L2 loss\n",
    "- analyze the effect of the different regularization methods on the parameter distribution.\n",
    "- think about early stopping and data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **reuse the code you wrote in the last exercise, or you can use the code we provide (below)**. Just copy the relevant parts into the cell below. Please **note that we extended the `Module` class** with a state to determine whether we're training or evaluating and two functions to toggle this state. We therefore also adapted the training loop function.\n",
    "\n",
    "The first task of this exercise is to implement Adam, you can **skip forward to the exercises by clicking [here](#adam)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classes: `Parameter` and `Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Optional, Tuple, Callable\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    \"\"\"A trainable parameter.\n",
    "\n",
    "    This class not only stores th_solution-Copy1e value of the parameter but also tensors/\n",
    "    properties associated with it, such as the gradient of the current backward\n",
    "    pass.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: np.ndarray, name: Optional[str] = None):\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        self.name = name\n",
    "        self.state_dict = dict()  # dict to store additional, optional information\n",
    "\n",
    "\n",
    "class Module:\n",
    "    \"\"\"The base class all network modules must inherit from.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Cache of the input of the forward pass.\n",
    "        # We need it during the backward pass in most layers,\n",
    "        #  e.g., to compute the gradient w.r.t to the weights.\n",
    "        self.input_cache = None\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, *args) -> np.ndarray:\n",
    "        \"\"\"Alias for forward, convenience function.\"\"\"\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def forward(self, *args) -> np.ndarray:\n",
    "        \"\"\"Compute the forward pass through the module.\n",
    "\n",
    "        Args:\n",
    "           args: The inputs, e.g., the output of the previous layer.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute the backward pass through the module.\n",
    "\n",
    "        This method computes the gradients with respect to the trainable\n",
    "        parameters and with respect to the first input.\n",
    "        If the module has trainable parameters, this method needs to update\n",
    "        the respective parameter.grad property.\n",
    "\n",
    "        Args:\n",
    "            grad: The gradient of the following layer.\n",
    "\n",
    "        Returns:\n",
    "            The gradient with respect to the first input argument. In general\n",
    "            it might be useful to return the gradients w.r.t. to all inputs, we\n",
    "            omit this here to keep things simple.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        \"\"\"Return the module parameters.\"\"\"\n",
    "        return []  # default to empty list\n",
    "\n",
    "    def train(self, mode : bool = True) -> 'Module':\n",
    "        \"\"\"Set the module to training mode.\n",
    "\n",
    "        This only affects some Modules, such as Dropout.\n",
    "        \n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        self.training = mode\n",
    "        return self\n",
    "\n",
    "    def eval(self) -> 'Module':\n",
    "        \"\"\"Set the module to evaluation mode.\n",
    "\n",
    "        This only affects some Modules, such as Dropout.\n",
    "\n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        return self.train(False)\n",
    "\n",
    "    def check_gradients(self, input_args: Tuple[np.ndarray]):\n",
    "        \"\"\"Verify the implementation of the gradients.\n",
    "\n",
    "        This includes the gradient with respect to the input as well as the\n",
    "        gradients w.r.t. the parameters if the module contains any.\n",
    "\n",
    "        As the scipy grad check only works on scalar functions, we compute\n",
    "        the sum over the output to obtain a scalar.\n",
    "        \"\"\"\n",
    "        assert isinstance(input_args, tuple), (\n",
    "            \"input_args must be a tuple but is {}\".format(type(input_args)))\n",
    "        TOLERANCE = 1e-6\n",
    "        self.check_gradients_wrt_input(input_args, TOLERANCE)\n",
    "        self.check_gradients_wrt_params(input_args, TOLERANCE)\n",
    "\n",
    "    def _zero_grad(self):\n",
    "        \"\"\"(Re-) intialize the param's grads to 0. Helper for grad checking.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.grad = np.zeros_like(p.data)\n",
    "\n",
    "    def check_gradients_wrt_input(self, input_args: Tuple[np.ndarray],\n",
    "                                  tolerance: float):\n",
    "        \"\"\"Verify the implementation of the module's gradient w.r.t. input.\"\"\"\n",
    "\n",
    "        def output_given_input(x: np.ndarray):\n",
    "            \"\"\"Wrap self.forward for scipy.optimize.check_grad.\"\"\"\n",
    "            # we only compute the gradient w.r.t. to the first input arg.\n",
    "            args = (x.reshape(input_args[0].shape),) + input_args[1:]\n",
    "            return np.sum(self.forward(*args))\n",
    "\n",
    "        def grad_given_input(x: np.ndarray):\n",
    "            \"\"\"Wrap self.backward for scipy.optimize.check_grad.\"\"\"\n",
    "            self._zero_grad()\n",
    "            # run self.forward to store the new input\n",
    "            args = (x.reshape(input_args[0].shape),) + input_args[1:]\n",
    "            out = self.forward(*args)\n",
    "            # compute the gradient w.r.t. to the input\n",
    "            return np.ravel(self.backward(np.ones_like(out)))\n",
    "\n",
    "        error = scipy.optimize.check_grad(\n",
    "            output_given_input, grad_given_input, np.ravel(input_args[0]))\n",
    "        num_outputs = np.prod(self.forward(*input_args).shape)\n",
    "        if np.squeeze(error) / num_outputs > tolerance:\n",
    "            raise RuntimeError(\"Check of gradient w.r.t. to input for {} failed.\"\n",
    "                               \"Error {:.4E} > {:.4E}.\"\n",
    "                               .format(self, np.squeeze(error), tolerance))\n",
    "\n",
    "    def check_gradients_wrt_params(self, input_args: Tuple[np.ndarray],\n",
    "                                   tolerance: float):\n",
    "        \"\"\"Verify the implementation of the module's gradient w.r.t. params.\"\"\"\n",
    "        for param in self.parameters():\n",
    "            def output_given_params(new_param: np.ndarray):\n",
    "                \"\"\"Wrap self.forward, change the parameters to new_param.\"\"\"\n",
    "                param.data = new_param.reshape(param.data.shape)\n",
    "                return np.sum(self.forward(*input_args))\n",
    "\n",
    "            def grad_given_params(new_param: np.ndarray):\n",
    "                self._zero_grad()\n",
    "                param.data = new_param.reshape(param.data.shape)\n",
    "                out = self.forward(*input_args)\n",
    "                # compute the gradient w.r.t. to param\n",
    "                self.backward(np.ones_like(out))\n",
    "                return np.ravel(param.grad)\n",
    "            # flatten the param as scipy can only handle 1D params\n",
    "            param_init = np.ravel(np.copy(param.data))\n",
    "            error = scipy.optimize.check_grad(output_given_params,\n",
    "                                              grad_given_params,\n",
    "                                              param_init)\n",
    "            num_outputs = np.prod(self.forward(*input_args).shape)\n",
    "            if np.squeeze(error) / num_outputs > tolerance:\n",
    "                raise RuntimeError(\"Check of gradient w.r.t. to param '{}' for\"\n",
    "                                   \"{} failed. Error {:.4E} > {:.4E}.\"\n",
    "                                   .format(param.name, self, error, tolerance))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions: `Relu` and `Softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Module):\n",
    "\n",
    "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
    "        # Shift input for numerical stability.\n",
    "        reduction_axes = tuple(range(1, len(z.shape)))\n",
    "        shift_z = z - np.max(z, axis=reduction_axes, keepdims=True)\n",
    "        exps = np.exp(shift_z)\n",
    "        h = exps / np.sum(exps, axis=reduction_axes, keepdims=True)\n",
    "        return h\n",
    "\n",
    "    def backward(self, grad) -> np.ndarray:\n",
    "        error_msg = (\"Softmax doesn't need to implement a gradient here, as it's\"\n",
    "                     \"only needed in CrossEntropyLoss, where we can simplify\"\n",
    "                     \"the gradient for the combined expression.\")\n",
    "        raise NotImplementedError(error_msg)\n",
    "\n",
    "\n",
    "class Relu(Module):\n",
    "\n",
    "    def forward(self, z: np.ndarray) -> np.ndarray:\n",
    "        self.input_cache = z\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        z = self.input_cache\n",
    "        return grad.reshape(z.shape) * np.where(z > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.W = Parameter(np.random.randn(out_features, in_features) * 0.01,\n",
    "                           name=\"W\")\n",
    "        self.b = Parameter(np.ones((out_features, 1)) * 0.01, name=\"b\")\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        assert len(x.shape) == 3, (\"x.shape should be (batch_size, input_size, 1)\"\n",
    "                                   \" but is {}.\".format(x.shape))\n",
    "        self.input_cache = x\n",
    "        z = self.W.data @ x + self.b.data\n",
    "        return z\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        x = self.input_cache\n",
    "        # remember that we have a batch dimension when transposing, i.e.,\n",
    "        # we need to use np.transpose instead of array.T\n",
    "        self.W.grad += np.sum(grad @ np.transpose(x, [0, 2, 1]), axis=0)\n",
    "        self.b.grad += np.sum(grad, axis=0)\n",
    "        return self.W.data.T @ grad\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        return self.W, self.b\n",
    "\n",
    "\n",
    "class Sequential(Module):\n",
    "    \"\"\"A sequential container to stack modules.\n",
    "\n",
    "    Modules will be added to it in the order they are passed to the\n",
    "    constructor.\n",
    "\n",
    "    Example network with one hidden layer:\n",
    "    model = Sequential(\n",
    "                  Linear(5,10),\n",
    "                  ReLU(),\n",
    "                  Linear(10,10),\n",
    "                )\n",
    "    \"\"\"\n",
    "    def __init__(self, *args: List[Module]):\n",
    "        super().__init__()\n",
    "        self.modules = args\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        for module in self.modules:\n",
    "            x = module(x)  # equivalent to module.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        for module in reversed(self.modules):\n",
    "            grad = module.backward(grad)\n",
    "        return grad\n",
    "\n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        # iterate over modules and retrieve their parameters, iterate over\n",
    "        # parameters to flatten the list\n",
    "        return [param for module in self.modules\n",
    "                for param in module.parameters()]\n",
    "    \n",
    "    def train(self, mode: bool = True) -> 'Sequential':\n",
    "        \"\"\"Set the train mode of the Sequential module and it's sub-modules.\n",
    "        \n",
    "        This only affects some modules, e.g., Dropout.\n",
    "        \n",
    "        Returns:\n",
    "            self.\n",
    "        \"\"\"\n",
    "        for module in self.modules:\n",
    "            module.train(mode)\n",
    "        return self\n",
    "\n",
    "\n",
    "def one_hot_encoding(y: np.ndarray, num_classes: int) -> np.ndarray:\n",
    "    \"\"\"Convert integer labels to one hot encoding.\n",
    "\n",
    "    Example: y=[1, 2] --> [[0, 1, 0], [0, 0, 2]]\n",
    "    \"\"\"\n",
    "    encoded = np.zeros(y.shape + (num_classes,))\n",
    "    encoded[np.arange(len(y)), y] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"The base class for optimizers.\n",
    "\n",
    "    All optimizers must implement a step() method that updates the parameters.\n",
    "    The general optimization loop then looks like this:\n",
    "\n",
    "    for inputs, targets in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    `zero_grad` initializes the gradients of the parameters to zero. This\n",
    "    allows to accumulate gradients (instead of replacing it) during\n",
    "    backpropagation, which is e.g. useful for skip connections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params: Iterable[Parameter]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            params: The parameters to be optimized.\n",
    "        \"\"\"\n",
    "        self._params = params\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Update the parameters.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        \"\"\"Clear the gradients of all optimized parameters.\"\"\"\n",
    "        for param in self._params:\n",
    "            assert isinstance(param, Parameter)\n",
    "            param.grad = np.zeros_like(param.data)\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    \"\"\"Stochastic Gradient Descent (SGD) optimizer with optional Momentum.\"\"\"\n",
    "\n",
    "    def __init__(self, params: Iterable[Parameter], lr: float,\n",
    "                 momentum: Optional[float] = None):\n",
    "        super().__init__(params)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        if momentum:\n",
    "            for param in self._params:\n",
    "                param.state_dict[\"momentum\"] = np.zeros_like(param.data)\n",
    "\n",
    "    def step(self):\n",
    "        for p in self._params:\n",
    "            if self.momentum:\n",
    "                # update the momentum\n",
    "                p.state_dict[\"momentum\"] *= self.momentum\n",
    "                p.state_dict[\"momentum\"] -= self.lr * p.grad\n",
    "                # update the parameter\n",
    "                p.data += p.state_dict[\"momentum\"]\n",
    "            else:\n",
    "                p.data -= self.lr * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    \"\"\"Compute the cross entropy.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def forward(self, a: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute the cross entropy, mean over batch size.\"\"\"\n",
    "        a = self.softmax(a)\n",
    "        self.input_cache = a, y\n",
    "#         print(\"len(a), a ...\", len(a))\n",
    "        # compute the mean over the batch\n",
    "        return -np.sum(np.log(a[y == 1])) / len(a)\n",
    "\n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        # we introduce the argument _ here, to have a unified interface with\n",
    "        # other Module objects. This simplifies code for gradient checking. \n",
    "        # We don't need this arg.\n",
    "        a, y = self.input_cache\n",
    "        grad = (a - y) / len(a)\n",
    "\n",
    "        # We have to recreate the batch dimension\n",
    "        grad = np.expand_dims(grad, -1)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, predictions, y_is_onehot: bool = False) -> float:\n",
    "    y_predicted = np.argmax(predictions, axis=-1)\n",
    "    y = np.argmax(y, axis=-1)\n",
    "    return np.sum(np.equal(y_predicted, y)) / len(y)\n",
    "\n",
    "\n",
    "def evaluate(data, labels, model, loss_fn, batch_size):\n",
    "    predictions = []\n",
    "    eval_cost = 0.\n",
    "    data_batched = minibatched(data, batch_size)\n",
    "    labels_batched = minibatched(labels, batch_size)\n",
    "\n",
    "    for x, y in zip(data_batched, labels_batched):\n",
    "        # note that when using cross entropy loss, the softmax is included in the\n",
    "        # loss and we'd need to apply it manually here to obtain the output as probabilities.\n",
    "        # However, softmax only rescales the outputs and doesn't change the argmax,\n",
    "        # so we'll skip this here, as we're only interested in the class prediction.\n",
    "        h_1 = np.squeeze(model(x))\n",
    "        predictions.append(h_1)\n",
    "        eval_cost += loss_fn(h_1, y)\n",
    "    predictions = np.array(predictions).reshape(-1, 10)\n",
    "    eval_accuracy = accuracy(y_val, predictions, False)\n",
    "    return eval_accuracy, eval_cost\n",
    "\n",
    "\n",
    "def train(model, loss_fn, optimizer, x_train, y_train, x_val, y_val,\n",
    "          num_epochs, batch_size, scheduler=None):\n",
    "    train_costs, train_accuracies = np.zeros(num_epochs), np.zeros(num_epochs)\n",
    "    eval_costs, eval_accuracies = np.zeros(num_epochs), np.zeros(num_epochs)\n",
    "    ix = np.arange(len(x_train))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {} / {}:\".format(epoch + 1, num_epochs))\n",
    "        print(\"LR---> \", optimizer.lr)\n",
    "        training_predictions = []\n",
    "        \n",
    "        np.random.shuffle(ix)\n",
    "        x_train_batched = minibatched(x_train[ix], batch_size)\n",
    "        y_train_batched = minibatched(y_train[ix], batch_size)\n",
    "        \n",
    "        # train for one epoch\n",
    "        model.train()\n",
    "        for x_batch, y_batch in zip(x_train_batched, y_train_batched):\n",
    "            optimizer.zero_grad()\n",
    "            y_batch_predicted = model(x_batch)\n",
    "            h_1 = np.squeeze(y_batch_predicted)\n",
    "            training_predictions.append(h_1)\n",
    "#             print(\"RIGHT BEFORE LOSS...\")\n",
    "            loss = loss_fn(h_1, y_batch)\n",
    "            grad = loss_fn.backward()\n",
    "            model.backward(grad)\n",
    "            optimizer.step()\n",
    "            train_costs[epoch] += loss\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        model.eval()\n",
    "       \n",
    "        training_predictions = np.array(training_predictions).reshape(-1, 10)\n",
    "        train_accuracies[epoch] = accuracy(y_train[ix], training_predictions, False)\n",
    "        print(\"  Training Accuracy: {:.4f}\".format(train_accuracies[epoch]))\n",
    "        print(\"  Training Cost: {:.4f}\".format(train_costs[epoch]))\n",
    "        eval_accuracies[epoch], eval_costs[epoch] = evaluate(x_val, y_val, model, loss_fn, batch_size)\n",
    "        print(\"  Eval Accuracy: {:.4f}\".format(eval_accuracies[epoch]))\n",
    "    return train_costs, train_accuracies, eval_costs, eval_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    \"\"\"Loads the data, returns training_data, validation_data, test_data.\"\"\"\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin1')\n",
    "\n",
    "\n",
    "def minibatched(data: np.ndarray, batch_size: int) -> List[np.ndarray]:\n",
    "    assert len(data) % batch_size == 0, (\"Data length {} is not multiple of batch size {}\"\n",
    "                                         .format(len(data), batch_size))\n",
    "    return data.reshape(-1, batch_size, *data.shape[1:])\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_mnist_data()\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_val = np.expand_dims(x_val, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = one_hot_encoding(y_train, num_classes)\n",
    "y_val = one_hot_encoding(y_val, num_classes)\n",
    "y_test = one_hot_encoding(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adam'></a>\n",
    "### Adam\n",
    "**Implement the step function** of the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-08):\n",
    "        super().__init__(params)\n",
    "        # we stick to the pytorch API, the variable names corresponding\n",
    "        # to the DL book are given in the comments\n",
    "        self.lr = lr  # lr is called epsilon in the DL book\n",
    "        self.betas = betas  # betas are called rho in the DL book\n",
    "        self.eps = eps  # eps is called delta in the DL book\n",
    "        self.t = 0\n",
    "        for param in self._params:\n",
    "            # first order moment variables, called m in the paper\n",
    "            param.state_dict[\"s\"] = np.zeros_like(param.data)\n",
    "            # second order moment variables, called v in the paper\n",
    "            param.state_dict[\"r\"] = np.zeros_like(param.data)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Update the parameters and decaying averages of past gradients.\"\"\"\n",
    "        # START TODO ################\n",
    "        self.t = self.t + 1\n",
    "        for param in self._params:\n",
    "            g = param.grad\n",
    "            param.state_dict[\"s\"] = self.betas[0] * param.state_dict[\"s\"] + (1.0 - self.betas[0]) * g\n",
    "            param.state_dict[\"r\"] = self.betas[1] * param.state_dict[\"r\"] + (1.0 - self.betas[1]) * g * g\n",
    "            \n",
    "            s_hat = param.state_dict[\"s\"] / (1.0 - np.power(self.betas[0], self.t))\n",
    "            r_hat = param.state_dict[\"r\"] / (1.0 - np.power(self.betas[1], self.t))\n",
    "            \n",
    "            del_theta = (-1.0 * self.lr * s_hat) / (self.eps + np.sqrt(r_hat))\n",
    "            param.data += del_theta\n",
    "        # END TODO###################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: Adam vs SGD vs SGD with Momentum\n",
    "\n",
    "**Train three models** (30 hidden units, relu) for 10 epochs, one with *Adam*, one with *SGD* and one with *SGD with momentum*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10:\n",
      "  Training Accuracy: 0.9115\n",
      "  Training Cost: 289.7934\n",
      "  Eval Accuracy: 0.9404\n",
      "Epoch 2 / 10:\n",
      "  Training Accuracy: 0.9493\n",
      "  Training Cost: 174.0971\n",
      "  Eval Accuracy: 0.9550\n",
      "Epoch 3 / 10:\n",
      "  Training Accuracy: 0.9559\n",
      "  Training Cost: 149.1114\n",
      "  Eval Accuracy: 0.9550\n",
      "Epoch 4 / 10:\n",
      "  Training Accuracy: 0.9606\n",
      "  Training Cost: 132.0193\n",
      "  Eval Accuracy: 0.9537\n",
      "Epoch 5 / 10:\n",
      "  Training Accuracy: 0.9631\n",
      "  Training Cost: 124.8119\n",
      "  Eval Accuracy: 0.9561\n",
      "Epoch 6 / 10:\n",
      "  Training Accuracy: 0.9655\n",
      "  Training Cost: 117.0844\n",
      "  Eval Accuracy: 0.9594\n",
      "Epoch 7 / 10:\n",
      "  Training Accuracy: 0.9666\n",
      "  Training Cost: 109.4440\n",
      "  Eval Accuracy: 0.9525\n",
      "Epoch 8 / 10:\n",
      "  Training Accuracy: 0.9683\n",
      "  Training Cost: 106.7652\n",
      "  Eval Accuracy: 0.9612\n",
      "Epoch 9 / 10:\n",
      "  Training Accuracy: 0.9695\n",
      "  Training Cost: 102.1679\n",
      "  Eval Accuracy: 0.9564\n",
      "Epoch 10 / 10:\n",
      "  Training Accuracy: 0.9706\n",
      "  Training Cost: 102.8703\n",
      "  Eval Accuracy: 0.9580\n",
      "ADAM DONE\n",
      "Epoch 1 / 10:\n",
      "  Training Accuracy: 0.9833\n",
      "  Training Cost: 53.5466\n",
      "  Eval Accuracy: 0.9656\n",
      "Epoch 2 / 10:\n",
      "  Training Accuracy: 0.9853\n",
      "  Training Cost: 46.9674\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 3 / 10:\n",
      "  Training Accuracy: 0.9859\n",
      "  Training Cost: 43.8772\n",
      "  Eval Accuracy: 0.9676\n",
      "Epoch 4 / 10:\n",
      "  Training Accuracy: 0.9865\n",
      "  Training Cost: 42.1121\n",
      "  Eval Accuracy: 0.9673\n",
      "Epoch 5 / 10:\n",
      "  Training Accuracy: 0.9874\n",
      "  Training Cost: 40.4828\n",
      "  Eval Accuracy: 0.9677\n",
      "Epoch 6 / 10:\n",
      "  Training Accuracy: 0.9883\n",
      "  Training Cost: 39.1537\n",
      "  Eval Accuracy: 0.9663\n",
      "Epoch 7 / 10:\n",
      "  Training Accuracy: 0.9881\n",
      "  Training Cost: 37.9730\n",
      "  Eval Accuracy: 0.9678\n",
      "Epoch 8 / 10:\n",
      "  Training Accuracy: 0.9884\n",
      "  Training Cost: 36.9858\n",
      "  Eval Accuracy: 0.9678\n",
      "Epoch 9 / 10:\n",
      "  Training Accuracy: 0.9882\n",
      "  Training Cost: 36.2040\n",
      "  Eval Accuracy: 0.9690\n",
      "Epoch 10 / 10:\n",
      "  Training Accuracy: 0.9889\n",
      "  Training Cost: 35.5622\n",
      "  Eval Accuracy: 0.9686\n",
      "SGD DONE\n",
      "Epoch 1 / 10:\n",
      "  Training Accuracy: 0.9603\n",
      "  Training Cost: 238.4743\n",
      "  Eval Accuracy: 0.9500\n",
      "Epoch 2 / 10:\n",
      "  Training Accuracy: 0.9632\n",
      "  Training Cost: 221.4239\n",
      "  Eval Accuracy: 0.9524\n",
      "Epoch 3 / 10:\n",
      "  Training Accuracy: 0.9631\n",
      "  Training Cost: 219.7502\n",
      "  Eval Accuracy: 0.9519\n",
      "Epoch 4 / 10:\n",
      "  Training Accuracy: 0.9651\n",
      "  Training Cost: 195.4040\n",
      "  Eval Accuracy: 0.9505\n",
      "Epoch 5 / 10:\n",
      "  Training Accuracy: 0.9656\n",
      "  Training Cost: 196.4631\n",
      "  Eval Accuracy: 0.9520\n",
      "Epoch 6 / 10:\n",
      "  Training Accuracy: 0.9642\n",
      "  Training Cost: 192.2236\n",
      "  Eval Accuracy: 0.9573\n",
      "Epoch 7 / 10:\n",
      "  Training Accuracy: 0.9665\n",
      "  Training Cost: 198.5981\n",
      "  Eval Accuracy: 0.9476\n",
      "Epoch 8 / 10:\n",
      "  Training Accuracy: 0.9646\n",
      "  Training Cost: 206.4500\n",
      "  Eval Accuracy: 0.9552\n",
      "Epoch 9 / 10:\n",
      "  Training Accuracy: 0.9681\n",
      "  Training Cost: 168.8109\n",
      "  Eval Accuracy: 0.9518\n",
      "Epoch 10 / 10:\n",
      "  Training Accuracy: 0.9679\n",
      "  Training Cost: 176.9227\n",
      "  Eval Accuracy: 0.9536\n",
      "SGDM DONE\n"
     ]
    }
   ],
   "source": [
    "linear_units = 30\n",
    "batch_size = 50\n",
    "num_epochs = 10\n",
    "sgd_learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "adam_learning_rate = 0.01\n",
    "\n",
    "# START TODO ################\n",
    "model = Sequential(Linear(784,linear_units), Relu(), Linear(linear_units,10))\n",
    "params = model.parameters()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "optim_ADAM = Adam(params, adam_learning_rate)\n",
    "optim_SGD = SGD(params, sgd_learning_rate)\n",
    "optim_SGDM = SGD(params, sgd_learning_rate, momentum)\n",
    "\n",
    "adam_tc, adam_ta, adam_vc, adam_va = train(model, loss_fn, optim_ADAM, x_train, y_train, x_val, y_val, num_epochs, batch_size)\n",
    "print(\"ADAM DONE\")\n",
    "sgd_tc, sgd_ta, sgd_vc, sgd_va = train(model, loss_fn, optim_SGD, x_train, y_train, x_val, y_val, num_epochs, batch_size)\n",
    "print(\"SGD DONE\")\n",
    "sgdm_tc, sgdm_ta, sgdm_vc, sgdm_va = train(model, loss_fn, optim_SGDM, x_train, y_train, x_val, y_val, num_epochs, batch_size)\n",
    "print(\"SGDM DONE\")\n",
    "# END TODO###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create two plots**, one for the training loss curves and one for the training accuracies curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "\n",
    "# START TODO ################\n",
    "# PLOT COSTS\n",
    "plt.figure(1)\n",
    "plt.plot(adam_tc, label='Adam_TC')\n",
    "plt.plot(adam_vc, label='Adam_VC')\n",
    "plt.plot(sgd_tc, label='SGD_TC')\n",
    "plt.plot(sgd_vc, label='SGD_VC')\n",
    "plt.plot(sgdm_tc, label='SGDM_TC')\n",
    "plt.plot(sgdm_vc, label='SGDM_VC')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('TRAINING AND VALIDATION COST')\n",
    "plt.xlabel('NUM OF EPOCHS')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(2)\n",
    "# Plot accuracies here\n",
    "# START TODO ################ \n",
    "plt.plot(adam_ta, label='Adam_TA')\n",
    "plt.plot(adam_va, label='Adam_VA')\n",
    "plt.plot(sgd_ta, label='SGD_TA')\n",
    "plt.plot(sgd_va, label='SGD_VA')\n",
    "plt.plot(sgdm_ta, label='SGDM_TA')\n",
    "plt.plot(sgdm_va, label='SGDM_VA')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('TRAINING AND VALIDATION ACCURACIES')\n",
    "plt.xlabel('NUM OF EPOCHS')\n",
    "# END TODO ##################\n",
    "\n",
    "plt.show()\n",
    "# END TODO###################D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Schedules\n",
    "\n",
    "Decreasing the learning rate can improve performance of the model.\n",
    "\n",
    "Pytorch implements learning rate schedules as wrappers for the optimizer and requires the user to call scheduler.step() after each epoch. (We've already done this for you in the training loop above)\n",
    "\n",
    "**Implement the learning rate scheduler** `PieceWiseConstantLR` and `CosineAnnealingLR`. You can use the provided `LambdaLR` class for this, which works analogously to the pytorch [LambdaLR](https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.LambdaLR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class LambdaLR:\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, lr_lambda: Callable[[int], float]):\n",
    "        \"\"\"Sets the learning rate to the initial lr times a given function.\n",
    "\n",
    "        Args:\n",
    "            optimizer: The optimzier to wrap.\n",
    "            lr_lambda: A function that takes the current epoch as an argument\n",
    "                and returns the corresponding learning rate.\n",
    "        \"\"\"\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "        self.last_epoch = 0\n",
    "        self.initial_lr = np.copy(optimizer.lr)\n",
    "        self.lr_lambda = lr_lambda\n",
    "        print(\"self.initial_lr...\", self.initial_lr)\n",
    "        self.scheduledLRs = []\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"To be called after each epoch. Update optimizer.lr\"\"\"\n",
    "        print(\"SCHEDULER.STEP()...\")\n",
    "        self.last_epoch += 1\n",
    "        self.optimizer.lr = self.lr_lambda(self.last_epoch)\n",
    "        self.scheduledLRs.append(self.optimizer.lr)\n",
    "        print(\"SCHEDULED LR...\", self.optimizer.lr)\n",
    "\n",
    "\n",
    "class PiecewiseConstantLR(LambdaLR):\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, epochs: List[int],\n",
    "                 learning_rates: List[float]):\n",
    "        \"\"\"Set learning rate as piecewise constant steps.\n",
    "\n",
    "        This class inherits from LambdaLR and implements the lambda\n",
    "        function that maps the current epoch to the learning rate\n",
    "        according to epochs.\n",
    "        \n",
    "        optimizer: The optimizer to wrap\n",
    "        \"\"\"\n",
    "        # START TODO ################\n",
    "        def pclr(cur_epo):\n",
    "            try:\n",
    "                index = next(idx for idx, val in enumerate(epochs) if val >= cur_epo)\n",
    "                print(\"index...\", index, learning_rates[index])\n",
    "                return learning_rates[index]\n",
    "            except StopIteration: return learning_rates[-1]\n",
    "    \n",
    "        super().__init__(optimizer, pclr)\n",
    "        # End TODO ################\n",
    "        \n",
    "class CosineAnnealingLR(LambdaLR):\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, T_max: int):\n",
    "        \"\"\"Set learning rate as a cosine decay.\n",
    "\n",
    "        This class inherits from LambdaLR and implements the lambda\n",
    "        function that maps the current epoch to the learning rate\n",
    "        according to epochs.\n",
    "        \n",
    "        optimizer: The optimizer to wrap\n",
    "        T_max:  Maximum number of epochs.\n",
    "        \"\"\"\n",
    "        # START TODO ################\n",
    "        def calr(cur_epo):\n",
    "            # self.eta_min + (base_lr - self.eta_min) * (1 + math.cos(math.pi * self.last_epoch / self.T_max)) / 2\n",
    "            lr = 0.5 * (1.0 + np.cos(np.pi * cur_epo / T_max)) * self.initial_lr\n",
    "            return lr\n",
    "        \n",
    "        super().__init__(optimizer, calr)\n",
    "        # End TODO ################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PYTORCH**\n",
    "$\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\\cos(\\frac{T_{cur}}{T_{max}}\\pi))$\n",
    "\n",
    "**IMPLEMENTED**\n",
    "$\\eta_t = \\frac{1}{2}(1 +\\cos(\\frac{T_{cur}}{T_{max}}\\pi))\\eta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify your implementation, **plot the learning rate schedules**, with the number of epochs on the x-axis and the learning rate on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.initial_lr... 0.01\n",
      "self.initial_lr... 0.01\n",
      "Epoch 1 / 40:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.00998458666866564\n",
      "  Training Accuracy: 0.9093\n",
      "  Training Cost: 303.7995\n",
      "  Eval Accuracy: 0.9414\n",
      "Epoch 2 / 40:\n",
      "LR--->  0.00998458666866564\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009938441702975689\n",
      "  Training Accuracy: 0.9440\n",
      "  Training Cost: 188.6881\n",
      "  Eval Accuracy: 0.9424\n",
      "Epoch 3 / 40:\n",
      "LR--->  0.009938441702975689\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009861849601988383\n",
      "  Training Accuracy: 0.9517\n",
      "  Training Cost: 160.1413\n",
      "  Eval Accuracy: 0.9549\n",
      "Epoch 4 / 40:\n",
      "LR--->  0.009861849601988383\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009755282581475769\n",
      "  Training Accuracy: 0.9566\n",
      "  Training Cost: 144.6540\n",
      "  Eval Accuracy: 0.9560\n",
      "Epoch 5 / 40:\n",
      "LR--->  0.009755282581475769\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009619397662556433\n",
      "  Training Accuracy: 0.9595\n",
      "  Training Cost: 133.7053\n",
      "  Eval Accuracy: 0.9522\n",
      "Epoch 6 / 40:\n",
      "LR--->  0.009619397662556433\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.00945503262094184\n",
      "  Training Accuracy: 0.9625\n",
      "  Training Cost: 125.8291\n",
      "  Eval Accuracy: 0.9538\n",
      "Epoch 7 / 40:\n",
      "LR--->  0.00945503262094184\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009263200821770462\n",
      "  Training Accuracy: 0.9644\n",
      "  Training Cost: 118.9882\n",
      "  Eval Accuracy: 0.9579\n",
      "Epoch 8 / 40:\n",
      "LR--->  0.009263200821770462\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.009045084971874737\n",
      "  Training Accuracy: 0.9654\n",
      "  Training Cost: 111.4545\n",
      "  Eval Accuracy: 0.9504\n",
      "Epoch 9 / 40:\n",
      "LR--->  0.009045084971874737\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.008802029828000156\n",
      "  Training Accuracy: 0.9688\n",
      "  Training Cost: 102.5385\n",
      "  Eval Accuracy: 0.9595\n",
      "Epoch 10 / 40:\n",
      "LR--->  0.008802029828000156\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.008535533905932738\n",
      "  Training Accuracy: 0.9707\n",
      "  Training Cost: 99.9112\n",
      "  Eval Accuracy: 0.9589\n",
      "Epoch 11 / 40:\n",
      "LR--->  0.008535533905932738\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.00824724024165092\n",
      "  Training Accuracy: 0.9717\n",
      "  Training Cost: 93.9475\n",
      "  Eval Accuracy: 0.9628\n",
      "Epoch 12 / 40:\n",
      "LR--->  0.00824724024165092\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.007938926261462366\n",
      "  Training Accuracy: 0.9726\n",
      "  Training Cost: 89.1601\n",
      "  Eval Accuracy: 0.9602\n",
      "Epoch 13 / 40:\n",
      "LR--->  0.007938926261462366\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0076124928235797445\n",
      "  Training Accuracy: 0.9740\n",
      "  Training Cost: 83.5468\n",
      "  Eval Accuracy: 0.9560\n",
      "Epoch 14 / 40:\n",
      "LR--->  0.0076124928235797445\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.007269952498697734\n",
      "  Training Accuracy: 0.9761\n",
      "  Training Cost: 76.0967\n",
      "  Eval Accuracy: 0.9600\n",
      "Epoch 15 / 40:\n",
      "LR--->  0.007269952498697734\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.00691341716182545\n",
      "  Training Accuracy: 0.9768\n",
      "  Training Cost: 74.5155\n",
      "  Eval Accuracy: 0.9592\n",
      "Epoch 16 / 40:\n",
      "LR--->  0.00691341716182545\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.006545084971874737\n",
      "  Training Accuracy: 0.9786\n",
      "  Training Cost: 67.8659\n",
      "  Eval Accuracy: 0.9610\n",
      "Epoch 17 / 40:\n",
      "LR--->  0.006545084971874737\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0061672268192795275\n",
      "  Training Accuracy: 0.9797\n",
      "  Training Cost: 63.7312\n",
      "  Eval Accuracy: 0.9609\n",
      "Epoch 18 / 40:\n",
      "LR--->  0.0061672268192795275\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0057821723252011546\n",
      "  Training Accuracy: 0.9829\n",
      "  Training Cost: 54.3582\n",
      "  Eval Accuracy: 0.9602\n",
      "Epoch 19 / 40:\n",
      "LR--->  0.0057821723252011546\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0053922954786392256\n",
      "  Training Accuracy: 0.9831\n",
      "  Training Cost: 52.5833\n",
      "  Eval Accuracy: 0.9621\n",
      "Epoch 20 / 40:\n",
      "LR--->  0.0053922954786392256\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9853\n",
      "  Training Cost: 46.9595\n",
      "  Eval Accuracy: 0.9605\n",
      "Epoch 21 / 40:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.004607704521360776\n",
      "  Training Accuracy: 0.9864\n",
      "  Training Cost: 41.0570\n",
      "  Eval Accuracy: 0.9602\n",
      "Epoch 22 / 40:\n",
      "LR--->  0.004607704521360776\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.004217827674798847\n",
      "  Training Accuracy: 0.9870\n",
      "  Training Cost: 38.6260\n",
      "  Eval Accuracy: 0.9632\n",
      "Epoch 23 / 40:\n",
      "LR--->  0.004217827674798847\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0038327731807204736\n",
      "  Training Accuracy: 0.9896\n",
      "  Training Cost: 32.0620\n",
      "  Eval Accuracy: 0.9618\n",
      "Epoch 24 / 40:\n",
      "LR--->  0.0038327731807204736\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.003454915028125263\n",
      "  Training Accuracy: 0.9902\n",
      "  Training Cost: 30.3429\n",
      "  Eval Accuracy: 0.9620\n",
      "Epoch 25 / 40:\n",
      "LR--->  0.003454915028125263\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0030865828381745515\n",
      "  Training Accuracy: 0.9915\n",
      "  Training Cost: 25.5857\n",
      "  Eval Accuracy: 0.9664\n",
      "Epoch 26 / 40:\n",
      "LR--->  0.0030865828381745515\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0027300475013022664\n",
      "  Training Accuracy: 0.9929\n",
      "  Training Cost: 22.3564\n",
      "  Eval Accuracy: 0.9644\n",
      "Epoch 27 / 40:\n",
      "LR--->  0.0027300475013022664\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.002387507176420256\n",
      "  Training Accuracy: 0.9932\n",
      "  Training Cost: 20.6661\n",
      "  Eval Accuracy: 0.9650\n",
      "Epoch 28 / 40:\n",
      "LR--->  0.002387507176420256\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0020610737385376348\n",
      "  Training Accuracy: 0.9949\n",
      "  Training Cost: 17.5297\n",
      "  Eval Accuracy: 0.9646\n",
      "Epoch 29 / 40:\n",
      "LR--->  0.0020610737385376348\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0017527597583490823\n",
      "  Training Accuracy: 0.9958\n",
      "  Training Cost: 14.6512\n",
      "  Eval Accuracy: 0.9626\n",
      "Epoch 30 / 40:\n",
      "LR--->  0.0017527597583490823\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0014644660940672626\n",
      "  Training Accuracy: 0.9964\n",
      "  Training Cost: 13.2193\n",
      "  Eval Accuracy: 0.9638\n",
      "Epoch 31 / 40:\n",
      "LR--->  0.0014644660940672626\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0011979701719998454\n",
      "  Training Accuracy: 0.9970\n",
      "  Training Cost: 11.1896\n",
      "  Eval Accuracy: 0.9649\n",
      "Epoch 32 / 40:\n",
      "LR--->  0.0011979701719998454\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0009549150281252633\n",
      "  Training Accuracy: 0.9975\n",
      "  Training Cost: 10.3425\n",
      "  Eval Accuracy: 0.9637\n",
      "Epoch 33 / 40:\n",
      "LR--->  0.0009549150281252633\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0007367991782295391\n",
      "  Training Accuracy: 0.9979\n",
      "  Training Cost: 8.9029\n",
      "  Eval Accuracy: 0.9641\n",
      "Epoch 34 / 40:\n",
      "LR--->  0.0007367991782295391\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0005449673790581611\n",
      "  Training Accuracy: 0.9983\n",
      "  Training Cost: 8.1615\n",
      "  Eval Accuracy: 0.9636\n",
      "Epoch 35 / 40:\n",
      "LR--->  0.0005449673790581611\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0003806023374435663\n",
      "  Training Accuracy: 0.9985\n",
      "  Training Cost: 7.4240\n",
      "  Eval Accuracy: 0.9638\n",
      "Epoch 36 / 40:\n",
      "LR--->  0.0003806023374435663\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.00024471741852423234\n",
      "  Training Accuracy: 0.9987\n",
      "  Training Cost: 6.8701\n",
      "  Eval Accuracy: 0.9637\n",
      "Epoch 37 / 40:\n",
      "LR--->  0.00024471741852423234\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001381503980116172\n",
      "  Training Accuracy: 0.9987\n",
      "  Training Cost: 6.4876\n",
      "  Eval Accuracy: 0.9637\n",
      "Epoch 38 / 40:\n",
      "LR--->  0.0001381503980116172\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 6.15582970243117e-05\n",
      "  Training Accuracy: 0.9988\n",
      "  Training Cost: 6.1905\n",
      "  Eval Accuracy: 0.9633\n",
      "Epoch 39 / 40:\n",
      "LR--->  6.15582970243117e-05\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 1.541333133436018e-05\n",
      "  Training Accuracy: 0.9988\n",
      "  Training Cost: 6.0015\n",
      "  Eval Accuracy: 0.9636\n",
      "Epoch 40 / 40:\n",
      "LR--->  1.541333133436018e-05\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0\n",
      "  Training Accuracy: 0.9988\n",
      "  Training Cost: 5.8807\n",
      "  Eval Accuracy: 0.9636\n",
      "Epoch 1 / 40:\n",
      "LR--->  0.0\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.1\n",
      "SCHEDULED LR... 0.1\n",
      "  Training Accuracy: 0.9988\n",
      "  Training Cost: 5.8388\n",
      "  Eval Accuracy: 0.9636\n",
      "Epoch 2 / 40:\n",
      "LR--->  0.1\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.1\n",
      "SCHEDULED LR... 0.1\n",
      "  Training Accuracy: 0.1971\n",
      "  Training Cost: 2200.8670\n",
      "  Eval Accuracy: 0.2110\n",
      "Epoch 3 / 40:\n",
      "LR--->  0.1\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.05\n",
      "SCHEDULED LR... 0.05\n",
      "  Training Accuracy: 0.2448\n",
      "  Training Cost: 1989.7737\n",
      "  Eval Accuracy: 0.2362\n",
      "Epoch 4 / 40:\n",
      "LR--->  0.05\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.05\n",
      "SCHEDULED LR... 0.05\n",
      "  Training Accuracy: 0.2700\n",
      "  Training Cost: 1857.6643\n",
      "  Eval Accuracy: 0.2786\n",
      "Epoch 5 / 40:\n",
      "LR--->  0.05\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.2859\n",
      "  Training Cost: 1808.1475\n",
      "  Eval Accuracy: 0.2840\n",
      "Epoch 6 / 40:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.2935\n",
      "  Training Cost: 1765.2164\n",
      "  Eval Accuracy: 0.2832\n",
      "Epoch 7 / 40:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.2938\n",
      "  Training Cost: 1751.6094\n",
      "  Eval Accuracy: 0.2994\n",
      "Epoch 8 / 40:\n",
      "LR--->  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHEDULER.STEP()...\n",
      "index... 3 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3026\n",
      "  Training Cost: 1733.2147\n",
      "  Eval Accuracy: 0.3043\n",
      "Epoch 9 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3052\n",
      "  Training Cost: 1728.0710\n",
      "  Eval Accuracy: 0.2999\n",
      "Epoch 10 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3044\n",
      "  Training Cost: 1723.8159\n",
      "  Eval Accuracy: 0.3065\n",
      "Epoch 11 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3089\n",
      "  Training Cost: 1719.9700\n",
      "  Eval Accuracy: 0.3089\n",
      "Epoch 12 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3112\n",
      "  Training Cost: 1715.9036\n",
      "  Eval Accuracy: 0.3115\n",
      "Epoch 13 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3136\n",
      "  Training Cost: 1711.6948\n",
      "  Eval Accuracy: 0.3143\n",
      "Epoch 14 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3184\n",
      "  Training Cost: 1706.4964\n",
      "  Eval Accuracy: 0.3205\n",
      "Epoch 15 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3249\n",
      "  Training Cost: 1698.3702\n",
      "  Eval Accuracy: 0.3287\n",
      "Epoch 16 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3336\n",
      "  Training Cost: 1685.8771\n",
      "  Eval Accuracy: 0.3435\n",
      "Epoch 17 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3442\n",
      "  Training Cost: 1668.5732\n",
      "  Eval Accuracy: 0.3502\n",
      "Epoch 18 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3593\n",
      "  Training Cost: 1646.3416\n",
      "  Eval Accuracy: 0.3598\n",
      "Epoch 19 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3682\n",
      "  Training Cost: 1623.4446\n",
      "  Eval Accuracy: 0.3857\n",
      "Epoch 20 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3769\n",
      "  Training Cost: 1603.3761\n",
      "  Eval Accuracy: 0.3814\n",
      "Epoch 21 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3820\n",
      "  Training Cost: 1587.4690\n",
      "  Eval Accuracy: 0.3917\n",
      "Epoch 22 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3854\n",
      "  Training Cost: 1573.4765\n",
      "  Eval Accuracy: 0.3991\n",
      "Epoch 23 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3878\n",
      "  Training Cost: 1560.6061\n",
      "  Eval Accuracy: 0.3856\n",
      "Epoch 24 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3903\n",
      "  Training Cost: 1549.0179\n",
      "  Eval Accuracy: 0.3879\n",
      "Epoch 25 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3901\n",
      "  Training Cost: 1538.9540\n",
      "  Eval Accuracy: 0.3894\n",
      "Epoch 26 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3926\n",
      "  Training Cost: 1528.4448\n",
      "  Eval Accuracy: 0.4049\n",
      "Epoch 27 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3956\n",
      "  Training Cost: 1520.6150\n",
      "  Eval Accuracy: 0.3846\n",
      "Epoch 28 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3952\n",
      "  Training Cost: 1513.3969\n",
      "  Eval Accuracy: 0.4092\n",
      "Epoch 29 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3959\n",
      "  Training Cost: 1507.8059\n",
      "  Eval Accuracy: 0.3917\n",
      "Epoch 30 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.3975\n",
      "  Training Cost: 1502.0470\n",
      "  Eval Accuracy: 0.4140\n",
      "Epoch 31 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4014\n",
      "  Training Cost: 1496.3421\n",
      "  Eval Accuracy: 0.3966\n",
      "Epoch 32 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4010\n",
      "  Training Cost: 1492.5288\n",
      "  Eval Accuracy: 0.4081\n",
      "Epoch 33 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4029\n",
      "  Training Cost: 1487.9983\n",
      "  Eval Accuracy: 0.3884\n",
      "Epoch 34 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4033\n",
      "  Training Cost: 1484.4360\n",
      "  Eval Accuracy: 0.4175\n",
      "Epoch 35 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4036\n",
      "  Training Cost: 1480.8610\n",
      "  Eval Accuracy: 0.3881\n",
      "Epoch 36 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4071\n",
      "  Training Cost: 1477.2710\n",
      "  Eval Accuracy: 0.4264\n",
      "Epoch 37 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4069\n",
      "  Training Cost: 1474.7053\n",
      "  Eval Accuracy: 0.4027\n",
      "Epoch 38 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4066\n",
      "  Training Cost: 1472.6990\n",
      "  Eval Accuracy: 0.4265\n",
      "Epoch 39 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4092\n",
      "  Training Cost: 1470.4712\n",
      "  Eval Accuracy: 0.4185\n",
      "Epoch 40 / 40:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.4116\n",
      "  Training Cost: 1467.5530\n",
      "  Eval Accuracy: 0.4075\n"
     ]
    }
   ],
   "source": [
    "# COSINE SCHEDULING\n",
    "num_epochs = 40\n",
    "\n",
    "linear_units = 30\n",
    "batch_size = 50\n",
    "sgd_learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "adam_learning_rate = 0.01\n",
    "\n",
    "model = Sequential(Linear(784, linear_units), Relu(), Linear(linear_units, 10))\n",
    "params = model.parameters()\n",
    "optim_ADAM = Adam(params, adam_learning_rate)\n",
    "cosine_scheduler = CosineAnnealingLR(optim_ADAM, num_epochs)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "adam_CA_tc, adam_CA_ta, adam_CA_vc, adam_CA_va = train(model, loss_fn, optim_ADAM, x_train, y_train, \\\n",
    "                                           x_val, y_val, num_epochs, batch_size, cosine_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CS PLOTS\n",
    "plt.figure()\n",
    "# plt.plot(adam_CA_tc, label='Adam_TC')\n",
    "# plt.plot(adam_CA_vc, label='Adam_VC')\n",
    "plt.plot(cosine_scheduler.scheduledLRs, label='SCHEDULED LRs')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('LEARNING RATE')\n",
    "plt.xlabel('NUM OF EPOCHS')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.initial_lr... 0.01\n",
      "Epoch 1 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9117\n",
      "  Training Cost: 292.4018\n",
      "  Eval Accuracy: 0.9515\n",
      "Epoch 2 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9468\n",
      "  Training Cost: 177.4651\n",
      "  Eval Accuracy: 0.9539\n",
      "Epoch 3 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9562\n",
      "  Training Cost: 147.5079\n",
      "  Eval Accuracy: 0.9562\n",
      "Epoch 4 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9585\n",
      "  Training Cost: 138.7661\n",
      "  Eval Accuracy: 0.9519\n",
      "Epoch 5 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9616\n",
      "  Training Cost: 128.9080\n",
      "  Eval Accuracy: 0.9592\n",
      "Epoch 6 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9638\n",
      "  Training Cost: 120.8783\n",
      "  Eval Accuracy: 0.9570\n",
      "Epoch 7 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9643\n",
      "  Training Cost: 116.7054\n",
      "  Eval Accuracy: 0.9628\n",
      "Epoch 8 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9675\n",
      "  Training Cost: 109.0043\n",
      "  Eval Accuracy: 0.9562\n",
      "Epoch 9 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9699\n",
      "  Training Cost: 104.6269\n",
      "  Eval Accuracy: 0.9559\n",
      "Epoch 10 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 0 0.01\n",
      "SCHEDULED LR... 0.01\n",
      "  Training Accuracy: 0.9689\n",
      "  Training Cost: 103.4875\n",
      "  Eval Accuracy: 0.9624\n",
      "Epoch 11 / 80:\n",
      "LR--->  0.01\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9705\n",
      "  Training Cost: 97.5156\n",
      "  Eval Accuracy: 0.9571\n",
      "Epoch 12 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9806\n",
      "  Training Cost: 61.6282\n",
      "  Eval Accuracy: 0.9651\n",
      "Epoch 13 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9832\n",
      "  Training Cost: 52.1453\n",
      "  Eval Accuracy: 0.9664\n",
      "Epoch 14 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9840\n",
      "  Training Cost: 51.6955\n",
      "  Eval Accuracy: 0.9636\n",
      "Epoch 15 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9838\n",
      "  Training Cost: 49.9609\n",
      "  Eval Accuracy: 0.9620\n",
      "Epoch 16 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9852\n",
      "  Training Cost: 46.7836\n",
      "  Eval Accuracy: 0.9668\n",
      "Epoch 17 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9852\n",
      "  Training Cost: 45.5398\n",
      "  Eval Accuracy: 0.9615\n",
      "Epoch 18 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9857\n",
      "  Training Cost: 44.5014\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 19 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9864\n",
      "  Training Cost: 41.7209\n",
      "  Eval Accuracy: 0.9640\n",
      "Epoch 20 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 1 0.005\n",
      "SCHEDULED LR... 0.005\n",
      "  Training Accuracy: 0.9874\n",
      "  Training Cost: 40.4405\n",
      "  Eval Accuracy: 0.9627\n",
      "Epoch 21 / 80:\n",
      "LR--->  0.005\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9879\n",
      "  Training Cost: 36.5274\n",
      "  Eval Accuracy: 0.9667\n",
      "Epoch 22 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9937\n",
      "  Training Cost: 21.1862\n",
      "  Eval Accuracy: 0.9667\n",
      "Epoch 23 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9954\n",
      "  Training Cost: 17.0879\n",
      "  Eval Accuracy: 0.9649\n",
      "Epoch 24 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9959\n",
      "  Training Cost: 15.7024\n",
      "  Eval Accuracy: 0.9677\n",
      "Epoch 25 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9960\n",
      "  Training Cost: 14.8798\n",
      "  Eval Accuracy: 0.9668\n",
      "Epoch 26 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9965\n",
      "  Training Cost: 14.1483\n",
      "  Eval Accuracy: 0.9683\n",
      "Epoch 27 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9967\n",
      "  Training Cost: 13.2901\n",
      "  Eval Accuracy: 0.9665\n",
      "Epoch 28 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9969\n",
      "  Training Cost: 12.6681\n",
      "  Eval Accuracy: 0.9670\n",
      "Epoch 29 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9974\n",
      "  Training Cost: 11.8099\n",
      "  Eval Accuracy: 0.9669\n",
      "Epoch 30 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9972\n",
      "  Training Cost: 11.5708\n",
      "  Eval Accuracy: 0.9668\n",
      "Epoch 31 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9976\n",
      "  Training Cost: 10.7175\n",
      "  Eval Accuracy: 0.9667\n",
      "Epoch 32 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9978\n",
      "  Training Cost: 10.3670\n",
      "  Eval Accuracy: 0.9664\n",
      "Epoch 33 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9978\n",
      "  Training Cost: 9.6870\n",
      "  Eval Accuracy: 0.9663\n",
      "Epoch 34 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9980\n",
      "  Training Cost: 9.3662\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 35 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9978\n",
      "  Training Cost: 9.1997\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 36 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9984\n",
      "  Training Cost: 8.4471\n",
      "  Eval Accuracy: 0.9666\n",
      "Epoch 37 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9983\n",
      "  Training Cost: 8.1086\n",
      "  Eval Accuracy: 0.9668\n",
      "Epoch 38 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9983\n",
      "  Training Cost: 7.8368\n",
      "  Eval Accuracy: 0.9648\n",
      "Epoch 39 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9985\n",
      "  Training Cost: 7.4610\n",
      "  Eval Accuracy: 0.9652\n",
      "Epoch 40 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 2 0.001\n",
      "SCHEDULED LR... 0.001\n",
      "  Training Accuracy: 0.9985\n",
      "  Training Cost: 7.0098\n",
      "  Eval Accuracy: 0.9667\n",
      "Epoch 41 / 80:\n",
      "LR--->  0.001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9989\n",
      "  Training Cost: 6.6532\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 42 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9990\n",
      "  Training Cost: 5.3724\n",
      "  Eval Accuracy: 0.9662\n",
      "Epoch 43 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9990\n",
      "  Training Cost: 5.0618\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 44 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.9681\n",
      "  Eval Accuracy: 0.9655\n",
      "Epoch 45 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.8943\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 46 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.8216\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 47 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.7741\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 48 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.7221\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 49 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.6604\n",
      "  Eval Accuracy: 0.9656\n",
      "Epoch 50 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "index... 3 0.0001\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9992\n",
      "  Training Cost: 4.6297\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 51 / 80:\n",
      "LR--->  0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.5871\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 52 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.5403\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 53 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.4971\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 54 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.4646\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 55 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.4137\n",
      "  Eval Accuracy: 0.9656\n",
      "Epoch 56 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.3786\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 57 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.3407\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 58 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.3168\n",
      "  Eval Accuracy: 0.9653\n",
      "Epoch 59 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.2662\n",
      "  Eval Accuracy: 0.9662\n",
      "Epoch 60 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.2470\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 61 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9993\n",
      "  Training Cost: 4.2048\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 62 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.1665\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 63 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.1301\n",
      "  Eval Accuracy: 0.9655\n",
      "Epoch 64 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.1068\n",
      "  Eval Accuracy: 0.9658\n",
      "Epoch 65 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.0695\n",
      "  Eval Accuracy: 0.9654\n",
      "Epoch 66 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.0338\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 67 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 4.0019\n",
      "  Eval Accuracy: 0.9661\n",
      "Epoch 68 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 3.9658\n",
      "  Eval Accuracy: 0.9659\n",
      "Epoch 69 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 3.9408\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 70 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 3.8988\n",
      "  Eval Accuracy: 0.9656\n",
      "Epoch 71 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 3.8738\n",
      "  Eval Accuracy: 0.9659\n",
      "Epoch 72 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.8450\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 73 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.8133\n",
      "  Eval Accuracy: 0.9657\n",
      "Epoch 74 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.7867\n",
      "  Eval Accuracy: 0.9662\n",
      "Epoch 75 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.7521\n",
      "  Eval Accuracy: 0.9655\n",
      "Epoch 76 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9994\n",
      "  Training Cost: 3.7182\n",
      "  Eval Accuracy: 0.9660\n",
      "Epoch 77 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.6869\n",
      "  Eval Accuracy: 0.9661\n",
      "Epoch 78 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.6636\n",
      "  Eval Accuracy: 0.9659\n",
      "Epoch 79 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.6363\n",
      "  Eval Accuracy: 0.9656\n",
      "Epoch 80 / 80:\n",
      "LR--->  0.0001\n",
      "SCHEDULER.STEP()...\n",
      "SCHEDULED LR... 0.0001\n",
      "  Training Accuracy: 0.9995\n",
      "  Training Cost: 3.6037\n",
      "  Eval Accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "# PIECEWISE SCHEDULING\n",
    "num_epochs = 80\n",
    "\n",
    "linear_units = 30\n",
    "batch_size = 50\n",
    "sgd_learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "adam_learning_rate = 0.01\n",
    "\n",
    "model = Sequential(Linear(784, linear_units), Relu(), Linear(linear_units, 10))\n",
    "params = model.parameters()\n",
    "optim_ADAM = Adam(params, adam_learning_rate)\n",
    "piecewise_scheduler = PiecewiseConstantLR(optim_ADAM, [10, 20, 40, 50], [0.01, 0.005, 0.001, 0.0001])\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "adam_PC_tc, adam_PC_ta, adam_PC_vc, adam_PC_va = train(model, loss_fn, optim_ADAM, x_train, y_train, \\\n",
    "                                           x_val, y_val, num_epochs, batch_size, piecewise_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PC PLOTS\n",
    "plt.figure()\n",
    "# plt.plot(adam_CA_tc, label='Adam_TC')\n",
    "# plt.plot(adam_CA_vc, label='Adam_VC')\n",
    "plt.plot(piecewise_scheduler.scheduledLRs, label='SCHEDULED LRs')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('LEARNING RATES')\n",
    "plt.xlabel('NUM OF EPOCHS')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Feedback on Exercise 3.1\n",
    "\n",
    "Hands on implementation of Adam and the LR Scheduling library functions was a good learning exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "In this part of the exercise we will take a look multiple regularizers.\n",
    "\n",
    "### Dropout\n",
    "**Fill in the missing gaps** for the implementation of the dropout regularization (Chapter 7.12 in the DL book).\n",
    "During training, the dropout layer randomly sets the input tensor to 0 with probability p and scales the remaining values accordingly. During evaluation, the dropout layer returns the identity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Module):\n",
    "    \"\"\"Set input elements to zero during training with probability p.\"\"\"\n",
    "\n",
    "    def __init__(self, p : float = 0.5, fix_seed=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p: Probability of an element to be zeroed. Default: 0.5.\n",
    "            fix_seed: If true, we always use the same seed in the forward pass.\n",
    "                This is only needed for gradient checking and should only be\n",
    "                set True for gradient checking.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        # START TODO ################\n",
    "        self.scale = 1.0 / (1.0 - p)\n",
    "        # END TODO ################\n",
    "        self.fix_seed = fix_seed\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply dropout during training.\n",
    "        \n",
    "        Set values to zero with probability p during training\n",
    "        and scale them by 1/(1-p). Returns identidy during\n",
    "        evaluation mode (--> self.training = False).\n",
    "\n",
    "        Note: This layer should work with all kinds of input shapes.\n",
    "        \"\"\" \n",
    "        if not self.training:\n",
    "            return x\n",
    "        if self.fix_seed:  # we need this for gradient checking \n",
    "            np.random.seed(0)\n",
    "        # START TODO ################\n",
    "        self.kill = np.random.binomial(1, self.p, size = x.shape[0])\n",
    "        x = x * self.kill * self.scale\n",
    "        return x\n",
    "        # END TODO ################\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        if not self.training:\n",
    "            raise ValueError(\"Model is set to evaluation mode.\")\n",
    "        # START TODO ################\n",
    "        if self.fix_seed:  # we need this for gradient checking \n",
    "            np.random.seed(0)\n",
    "        # START TODO ################\n",
    "        kill = np.random.binomial(1, self.p, size = x.shape[0])\n",
    "        grad = grad * self.kill * self.scale\n",
    "        return grad\n",
    "        # END TODO ################\n",
    "\n",
    "# Check the gradient implementation\n",
    "x = np.random.rand(1, 1, 4, 4)\n",
    "Dropout(fix_seed=True).check_gradients((x,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1/L2 regularization\n",
    "**Implement $L_1$/$L_2$ regularization**. This is one of the rare cases where we differ from the pytorch API. The reason is that pytorch implements $L_2$ regularization in the optimizer but calles it `weight_decay` (which is actually a different operation if you're not using SGD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Check of gradient w.r.t. to param 'None' for<__main__.L1Regularization object at 0x000002593AAB8BA8> failed. Error 6.3640E+00 > 1.0000E-06.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-7836164a5c2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1Regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL2Regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_gradients_wrt_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_gradients_wrt_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fb345701e6b7>\u001b[0m in \u001b[0;36mcheck_gradients_wrt_params\u001b[1;34m(self, input_args, tolerance)\u001b[0m\n\u001b[0;32m    151\u001b[0m                 raise RuntimeError(\"Check of gradient w.r.t. to param '{}' for\"\n\u001b[0;32m    152\u001b[0m                                    \u001b[1;34m\"{} failed. Error {:.4E} > {:.4E}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                                    .format(param.name, self, error, tolerance))\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Check of gradient w.r.t. to param 'None' for<__main__.L1Regularization object at 0x000002593AAB8BA8> failed. Error 6.3640E+00 > 1.0000E-06."
     ]
    }
   ],
   "source": [
    "class L1Regularization(Module):\n",
    "\n",
    "    def __init__(self, alpha: float, parameters: List[Parameter]):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.params = parameters\n",
    "    \n",
    "    def forward(self) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "#         for param in self.params:\n",
    "#             param.data += self.alpha * np.sum(np.abs(param.data))\n",
    "        return np.array([param.data for param in self.params])\n",
    "        # END TODO ################\n",
    "\n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "#         back = np.array([param.grad for param in self.params])\n",
    "#         print(\"BACK.shape\", back.shape)\n",
    "        for param in self.params:\n",
    "            print(param.name)\n",
    "            param.grad += self.alpha\n",
    "        return np.array([param.grad for param in self.params])\n",
    "        # END TODO ################\n",
    "        \n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        return self.params\n",
    "\n",
    "        \n",
    "class L2Regularization(Module):\n",
    "\n",
    "    def __init__(self, alpha: float, parameters: List[Parameter]):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.params = parameters\n",
    "    \n",
    "    def forward(self) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "        return self.params[0].data\n",
    "        # END TODO ################\n",
    "\n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        # START TODO ################\n",
    "        for param in self.params:\n",
    "            print(param.name)\n",
    "            param.grad += (self.alpha * param.data) / (2 * param.data.shape[0])\n",
    "        return self.params[0].grad\n",
    "        # END TODO ################\n",
    "        \n",
    "    def parameters(self) -> List[Parameter]:\n",
    "        return self.params\n",
    "\n",
    "\n",
    "# Check the gradient implementation. Here we can only check w.r.t. the parameters.\n",
    "params = [Parameter(np.random.rand(50, 1) * 0.1)]\n",
    "print(params[0].grad)\n",
    "l1 = L1Regularization(0.1, params)\n",
    "l2 = L2Regularization(0.1, params)\n",
    "l1.check_gradients_wrt_params((), 1e-6)\n",
    "l2.check_gradients_wrt_params((), 1e-6)\n",
    "\n",
    "\n",
    "class RegularizedCrossEntropy(Module):\n",
    "    \"\"\"Combines Cross Entropy loss and Regularization loss by summing them.\"\"\"\n",
    "    \n",
    "    def __init__(self, regularization_loss: Module):\n",
    "        self.reg_loss = regularization_loss\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, a: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        return self.cross_entropy(a, y) + self.reg_loss()\n",
    "        \n",
    "    def backward(self, _=None) -> np.ndarray:\n",
    "        self.reg_loss.backward()  # this updates parameter gradients, no grad w.r.t input\n",
    "        return self.cross_entropy.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the effect of regularization on the model parameters.\n",
    "We'll do that with **four trained models**:\n",
    "1. Without regularization. It's always a good idea to train your model without any regularization first. Not only to have a baseline but also to check if your model is able to overfit the training data. If it can't overfit, it's likely not powerful enough or there's an error in the implementation. \n",
    "2. With L2 regularization, alpha = 0.0001, on the weight parameters (not on the bias)\n",
    "3. With L1 regularization, alpha = 0.0001, on the weight parameters (not on the bias)\n",
    "4. With Dropout, drop_probability = 0.3 for the input, drop_probability = 0.5 for the hidden layers.\n",
    "\n",
    "*Note* that in this case L1/L2/Dropout lead to worse accuracies. This is due to the fact that we use only 30 linear units to keep training times short, which already imposes strong regularization. In practice, we would select a more powerful model. However, the small model still nicely exhibits the effect of regularization on the distribution of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No regularization.\n",
      "Epoch 1 / 5:\n",
      "LR--->  0.05\n",
      "  Training Accuracy: 0.8830\n",
      "  Training Cost: 378.1924\n",
      "  Eval Accuracy: 0.9454\n",
      "Epoch 2 / 5:\n",
      "LR--->  0.05\n",
      "  Training Accuracy: 0.9519\n",
      "  Training Cost: 162.2500\n",
      "  Eval Accuracy: 0.9582\n",
      "Epoch 3 / 5:\n",
      "LR--->  0.05\n",
      "  Training Accuracy: 0.9587\n",
      "  Training Cost: 133.8660\n",
      "  Eval Accuracy: 0.9631\n",
      "Epoch 4 / 5:\n",
      "LR--->  0.05\n",
      "  Training Accuracy: 0.9650\n",
      "  Training Cost: 114.0466\n",
      "  Eval Accuracy: 0.9625\n",
      "Epoch 5 / 5:\n",
      "LR--->  0.05\n",
      "  Training Accuracy: 0.9681\n",
      "  Training Cost: 102.3517\n",
      "  Eval Accuracy: 0.9633\n",
      "L2 regularization.\n",
      "L1 regularization.\n",
      "Dropout.\n",
      "Epoch 1 / 5:\n",
      "LR--->  0.05\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50,10,50) (50,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-77d68870d275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"drop\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m train(models[\"drop\"], cross_entropy, optimizer, x_train, y_train,\n\u001b[1;32m---> 55\u001b[1;33m       x_val, y_val, num_epochs=num_epochs, batch_size=batch_size)\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m# END TODO ################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-c5cdec61794d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_fn, optimizer, x_train, y_train, x_val, y_val, num_epochs, batch_size, scheduler)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#             print(\"RIGHT BEFORE LOSS...\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-eeeedf521b4a>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# We don't need this arg.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# We have to recreate the batch dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50,10,50) (50,10) "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.05\n",
    "momentum = 0.9\n",
    "linear_units = 30\n",
    "alpha_l1 = 0.0001\n",
    "alpha_l2 = 0.0001\n",
    "\n",
    "def build_model():\n",
    "    return Sequential(Linear(784, linear_units),\n",
    "                      Relu(),\n",
    "                      Linear(linear_units, 10))\n",
    "\n",
    "\n",
    "def build_model_dropout():\n",
    "    return Sequential(Dropout(0.3),\n",
    "                      Linear(784, linear_units),\n",
    "                      Relu(),\n",
    "                      Dropout(0.5),\n",
    "                      Linear(linear_units, 10))\n",
    "\n",
    "models = {}  # dict to store the trained models\n",
    "# let's save a model, which we won't train, to get the initial parameter distribution\n",
    "models[\"before_training\"] = build_model()\n",
    "\n",
    "# no regularization\n",
    "print(\"No regularization.\")\n",
    "models[\"no_reg\"] = build_model()\n",
    "params = [p for p in models[\"no_reg\"].parameters() if \"W\" in p.name]\n",
    "cross_entropy = CrossEntropyLoss()\n",
    "optimizer = SGD(models[\"no_reg\"].parameters(), lr=learning_rate, momentum=momentum)\n",
    "train(models[\"no_reg\"], cross_entropy, optimizer, x_train, y_train,\n",
    "      x_val, y_val, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# START TODO ################\n",
    "\n",
    "\n",
    "# L2 regularization\n",
    "print(\"L2 regularization.\")\n",
    "\n",
    "\n",
    "\n",
    "# L1 regularization\n",
    "print(\"L1 regularization.\")\n",
    "\n",
    "\n",
    "\n",
    "# dropout\n",
    "print(\"Dropout.\")\n",
    "models[\"drop\"] = build_model_dropout()\n",
    "params = [p for p in models[\"drop\"].parameters() if \"W\" in p.name]\n",
    "cross_entropy = CrossEntropyLoss()\n",
    "optimizer = SGD(models[\"drop\"].parameters(), lr=learning_rate, momentum=momentum)\n",
    "train(models[\"drop\"], cross_entropy, optimizer, x_train, y_train,\n",
    "      x_val, y_val, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "# END TODO ################\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the parameter distribution of the four models by **plotting the histogram of their weight values from -1 to 1 with 100 bins**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TODO ################\n",
    "no_reg_W = [p for p in models[\"no_reg\"].parameters() if \"W\" in p.name]\n",
    "# dropout_W = [p for p in models[\"drop\"].parameters() if \"W\" in p.name]\n",
    "\n",
    "plt.figure()\n",
    "bins = np.linspace(-1.0, 1.0, 100, endpoint=True)\n",
    "plt.hist(no_reg_W[0].data, bins, histtype='bar', rwidth=0.5)\n",
    "plt.hist(no_reg_W[1].data, bins, histtype='bar', rwidth=0.5)\n",
    "# plt.hist(dropout_W, bins, histtype='bar', rwidth=0.5)\n",
    "plt.xlabel('BINS')\n",
    "plt.ylabel('WEIGHTS')\n",
    "plt.title('WEIGHTS HIST')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# End TODO ################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation increases model generalization by increasing the training set with fake data.\n",
    "\n",
    "**Question:** State *five effective operations* to generate fake data on the *MNIST dataset*. State *one operation* which doesn't make sense and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "**1)** Flip the image.\n",
    "\n",
    "**2)** Rotate the image.\n",
    "\n",
    "**3)** Scaling.\n",
    "\n",
    "**4)** Crop.\n",
    "\n",
    "**5)** Adding Gaussian Noise.\n",
    "\n",
    "Adding Gaussian noise probably does not make much sense because our main objective of doing data augmentation is to make the model learn image features/objects irrespective of its positions or orientations in the image, but adding gaussian noise has nothing to do with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Another very popular technique in deep learning is *early stopping* (deeplearning book, section 7.8). \n",
    "\n",
    "![Figure 7.3 from the DeepLearningBook](learning-curve-dl-fig-7-3.png \"TEST\")\n",
    "\n",
    "**Questions:**\n",
    "How do the given loss curves (deep learning book, figure 7.3) relate to *early stopping*?\n",
    "Why is it a regularization technique? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "From the diagram, it can be seen that validation set loss stops decreasing after 20 epochs (approx) while the training loss goes on decreasing till it becomes zero (approx) after 50 epochs. Its a clear sign of overfitting, so we need to stop training the model after a certain number of epochs (maybe at 25th epoch) when this situation happens.\n",
    "\n",
    "It is a regularization technique because we are not allowing our model to get trained when it overfits by stopping the training process early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Feedback on Exercise 3.2\n",
    "\n",
    "Unable to finish the code for L1 and L2 reg., although we understand the concept but somehow found the code to be a little tricky to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
